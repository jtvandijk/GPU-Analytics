{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Address geocoding \n",
    "\n",
    "Address geocoding, or address matching, is an example of a broad class of data science problems known as data linkage. Data linkage problems involve connecting two datasets together by establishing an association between two records based on one or more common properties. In the case of address geocoding, one would try to assign XY coordinates to a list of address strings derived from, for instance, consumer sources that are not explicitly georeferenced (see, for instance, Lansley et al. 2019). The process involves linking the address list to an authoritative reference database that contains address strings with their associated coordinates. However, due to the lack of a universal standard on how addresses are structured and stored, matching addresses becomes a significantly complicated task that requires a great deal of data preparation and processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective \n",
    "\n",
    "Not only is address matching problem a complex problem, its complexity increases exponentially with an increase in data sizes. The objective of this first Case Study, therefore, is to showcase how we can utilise a GPUâ€™s processing capabilities for address matching - and data linkage more genera"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries and Data pre-processing\n",
    "\n",
    "In this tutorial, we will be using two US hospital data sets. The first data set contains hospital banking details. The second data set contains information on payments hospitals have received from the insurance provider. The goal is link these two datasets for further analysis.\n",
    "\n",
    "We start by importing the libraries that we will need, loading the individual data sets, and concatenating the individual address components in each of the data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf,cuml,cupy \n",
    "import pandas as pd\n",
    "from cuml.feature_extraction.text import TfidfVectorizer as GPU_TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as CPU_TfidfVectorizer\n",
    "import time \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import data\n",
    "data1_url = \"https://raw.githubusercontent.com/chris1610/pbpython/master/data/hospital_account_info.csv\"\n",
    "data2_url = \"https://raw.githubusercontent.com/chris1610/pbpython/master/data/hospital_reimbursement.csv\"\n",
    "\n",
    "account = pd.read_csv(data1_url) #Hospital account information\n",
    "reimbursement = pd.read_csv(data2_url) #Hospital reimbursement information\n",
    "\n",
    "#Converting facility name, address, city and state into one string \n",
    "account_full_address = account.apply(lambda x: \" \".join([x['Facility Name'],x['Address'],x['City'],x['State']]), axis=1).to_list() \n",
    "\n",
    "reimbursement_full_address = reimbursement.apply(lambda x: \" \".join([x['Provider Name'],x['Provider Street Address'],x['Provider City'],x['Provider State']]), axis=1).to_list() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |   Provider_Num | Provider Name                    | Provider Street Address    | Provider City   | Provider State   |   Provider Zip Code |   Total Discharges |   Average Covered Charges |   Average Total Payments |   Average Medicare Payments |\n",
      "|---:|---------------:|:---------------------------------|:---------------------------|:----------------|:-----------------|--------------------:|-------------------:|--------------------------:|-------------------------:|----------------------------:|\n",
      "|  0 |         839987 | SOUTHEAST ALABAMA MEDICAL CENTER | 1108 ROSS CLARK CIRCLE     | DOTHAN          | AL               |               36301 |                118 |                   20855.6 |                  5026.19 |                     4115.52 |\n",
      "|  1 |         519118 | MARSHALL MEDICAL CENTER SOUTH    | 2505 U S HIGHWAY 431 NORTH | BOAZ            | AL               |               35957 |                 43 |                   13289.1 |                  5413.63 |                     4490.93 |\n",
      "|    |   Account_Num | Facility Name               | Address                   | City         | State   |   ZIP Code | County Name   | Phone Number   | Hospital Type             | Hospital Ownership             |\n",
      "|---:|--------------:|:----------------------------|:--------------------------|:-------------|:--------|-----------:|:--------------|:---------------|:--------------------------|:-------------------------------|\n",
      "|  0 |         10605 | SAGE MEMORIAL HOSPITAL      | STATE ROUTE 264 SOUTH 191 | GANADO       | AZ      |      86505 | APACHE        | (928) 755-4541 | Critical Access Hospitals | Voluntary non-profit - Private |\n",
      "|  1 |         24250 | WOODRIDGE BEHAVIORAL CENTER | 600 NORTH 7TH STREET      | WEST MEMPHIS | AR      |      72301 | CRITTENDEN    | (870) 394-4113 | Psychiatric               | Proprietary                    |\n"
     ]
    }
   ],
   "source": [
    "print(reimbursement.head(2).to_markdown())\n",
    "print(account.head(2).to_markdown())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorization - experimenting the effect of data size on computational time\n",
    "Now we are set-up, let's encode the full address with TFIDF. we can assess the impact of data size on computational time for both our CPU and GPU approach. To allow for a fair comparison between the CPU and GPU, we will be using the same data set and increase the size by the data set by x times on each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inititate sklearn vectoriser and cuml vectosier \n",
    "\n",
    "#CPU vectorizer from sklearn \n",
    "cpu_vectorizer = CPU_TfidfVectorizer(analyzer='char',ngram_range=(1,2))\n",
    "#GPU vectorizer from cuml \n",
    "gpu_vectorizer = GPU_TfidfVectorizer(analyzer='char',ngram_range=(1,2))\n",
    "\n",
    "#Here analyzer='char' means we are using character as the input \n",
    "#ngram_range = (1,2) means we are looking at both unigram and bigram for the model input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually inflating number of rows with 10 run times \n",
    "total_datasize = []\n",
    "cpu_time = []\n",
    "gpu_time = [] \n",
    "for run in range(1,10):\n",
    "  for i in range(1,10):\n",
    "    #Manually inflating the number of records \n",
    "    input = reimbursement_full_address*i\n",
    "    total_datasize.append(len(input))\n",
    "    #Cpu runtime \n",
    "    start = time.time()\n",
    "    cpu_output = cpu_vectorizer.fit_transform(input)\n",
    "    done = time.time()\n",
    "    elapsed = done - start \n",
    "    cpu_time.append(elapsed)\n",
    "\n",
    "    #gpu runtime \n",
    "    start = time.time()\n",
    "    #Convert input to cudf series \n",
    "    gpu_output = gpu_vectorizer.fit_transform(cudf.Series(input))\n",
    "    done = time.time()\n",
    "    elapsed = done - start \n",
    "    gpu_time.append(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "gpu_elapsed = pd.DataFrame({\"time\":gpu_time,\"data_size\":total_datasize,'label':\"gpu\"})\n",
    "cpu_elapsed = pd.DataFrame({\"time\":cpu_time,\"data_size\":total_datasize,'label':\"cpu\"})\n",
    "result = pd.concat([gpu_elapsed,cpu_elapsed]).reset_index()\n",
    "sns.lineplot(x= 'data_size',y='time',hue = 'label',data = result,ax = ax )\n",
    "plt.xlabel('Data Size')\n",
    "plt.ylabel(\"Time Elapsed \")\n",
    "plt.title(\"Comparing the speed of TF-IDF vectorisation on CPU and GPU\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consine similarity - experimenting the effect of matrix multiplication on computational time\n",
    "\n",
    "Now that we have our TF-IDF matrix, we want to use the hospital reimbursement data to find the most relevant address from the hospital data. To do this, we can find the address with the smallest distance (or highest similarity) to our query address. For the second step, we will compare the speed of computing the cosine similarity using the CPU and GPU. We do this by comparing the computation time of calculating the pair-wise cosine similarity between two matrices using NumPy, CuPy and Numba [OPTIONAL] from scratch. We will use the TF-IDF matrix we created from the reimbursement data in the previous step as the input, and hospital data as the target. For more details about cosine similarity and how to calculate it, please refer to this link.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_target =cpu_vectorizer.transform(account_full_address)\n",
    "gpu_target = gpu_vectorizer.transform(cudf.Series(account_full_address))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np \n",
    "import scipy\n",
    "import gc\n",
    "import torch \n",
    "from cupyx.scipy.sparse.linalg import norm as cp_norm\n",
    "from scipy.sparse.linalg import norm as sc_norm \n",
    "\n",
    "def np_cosine_similarity(query, target):\n",
    "    # Assert that the input matrices have the same number of columns\n",
    "    assert(query.shape[1] == target.shape[1])\n",
    "\n",
    "    #Calculate the dot product \n",
    "    dot_product = np.dot(query,target.T)\n",
    "\n",
    "    #Calculate l2 norm for query and target \n",
    "    query_norm = sc_norm(query,axis=1)\n",
    "    target_norm = sc_norm(target,axis=1)\n",
    "\n",
    "    return dot_product/(query_norm[:,np.newaxis]*target_norm[:,np.newaxis].T)\n",
    "\n",
    "#Cupy is a drop-in replacement for numpy \n",
    "def cp_cosine_similarity(query, target):\n",
    "    # Assert that the input matrices have the same number of columns\n",
    "    assert(query.shape[1] == target.shape[1])\n",
    "    #Initiate GPU instance \n",
    "    with cp.cuda.Device(0):\n",
    "        #Create memory pool\n",
    "        pool = cp.get_default_memory_pool()\n",
    "        pool.set_limit(1e9)  # Set the limit of the memory pool to 1 GB\n",
    "        \n",
    "        #Check whether the sparse matrix is compatible with Cupy, if not then convert\n",
    "        if isinstance(query,scipy.sparse._csr.csr_matrix) and isinstance(target,scipy.sparse._csr.csr_matrix):\n",
    "        # Convert the input matrices to sparse format and copy to the GPU\n",
    "            query = cp.sparse.csr_matrix(query, copy=True) \n",
    "            target = cp.sparse.csr_matrix(target, copy=True)\n",
    "        \n",
    "        # Dot product using cupy.dot()\n",
    "        dot_product = query.dot(target.T)\n",
    "        \n",
    "        # Calculate l2 norm for query and target\n",
    "        query_norm = cp_norm(query,axis=1)\n",
    "        target_norm = cp_norm(target,axis=1)\n",
    "        \n",
    "        # Compute the cosine similarity\n",
    "        output = dot_product / (cp.expand_dims(query_norm,axis=1) * cp.expand_dims(target_norm,axis=0))\n",
    "        \n",
    "        #Converting back to numpy array\n",
    "        result = output.get()\n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "#Is a JIT compiler for python\n",
    "#You can take function with numerical values or arrays\n",
    "#And compile them to assembley, so they run at high speed \n",
    "#Deploy to compiled on GPU and CUDA \n",
    "\n",
    "#Define the kernel for calculation \n",
    "#- A GPU function launched by the host and executed on the device\n",
    "#Cannot explicity return a numerical value \n",
    "@cuda.jit\n",
    "def pairwise_cosine_similarity(A, B, C):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < C.shape[0] and j < C.shape[1]:\n",
    "        dot = 0.0\n",
    "        normA = 0.0\n",
    "        normB = 0.0\n",
    "        for k in range(A.shape[1]):\n",
    "            a = A[i, k]\n",
    "            b = B[j, k]\n",
    "            dot += a * b\n",
    "            normA += a ** 2\n",
    "            normB += b ** 2\n",
    "        C[i, j] = dot / (normA * normB)**0.5\n",
    "\n",
    "def Numba_cuda_cosine_similarity(query,target): \n",
    "     # Assert that the input matrices have the same number of columns\n",
    "    assert(query.shape[1] == target.shape[1])\n",
    "    ## Allocate memory on the device for the result\n",
    "    output = cuda.device_array((query.shape[0],target.shape[0]))\n",
    "\n",
    "\n",
    "    # Convert the input matrices to sparse format and copy to the GPU\n",
    "    query = cuda.to_device(query.toarray())\n",
    "    target = cuda.to_device(target.toarray()) \n",
    "    #Set the number of threads in a block ----- \n",
    "    threadsperblock = (32,32)\n",
    "\n",
    "    # Calculate the number of thread blocks in the grid \n",
    "    blockspergrid_x = (output.shape[0] + (threadsperblock[0] - 1)) // threadsperblock[0]\n",
    "    blockspergrid_y = (output.shape[1] + (threadsperblock[1] - 1)) // threadsperblock[1]\n",
    "    blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "\n",
    "    #Starting the kernel \n",
    "    pairwise_cosine_similarity[blockspergrid, threadsperblock](query, target, output)\n",
    "\n",
    "    # Copy the result back to the host\n",
    "    return output.copy_to_host()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "total_datasize = []\n",
    "cpu_time = []\n",
    "gpu_time = [] \n",
    "numba_time = [] \n",
    "\n",
    "for size in tqdm(range(1000,cpu_output.shape[0],5000)):\n",
    "    total_datasize.append(size)\n",
    "    query = cpu_output[0:size,]\n",
    "    #CPU --------------\n",
    "    start = time.time()\n",
    "    _ = np_cosine_similarity(query,cpu_target)\n",
    "    done = time.time()\n",
    "    elapsed = done - start \n",
    "    cpu_time.append(elapsed)\n",
    "    \n",
    "    #GPU --------------\n",
    "    start = time.time()\n",
    "    _ = cp_cosine_similarity(query,cpu_target)\n",
    "    done = time.time()\n",
    "    elapsed = done - start \n",
    "    gpu_time.append(elapsed)\n",
    "\n",
    "    #Numba CUDA ---- \n",
    "    start = time.time()\n",
    "    _ = Numba_cuda_cosine_similarity(query,cpu_target)\n",
    "    done = time.time()\n",
    "    elapsed = done - start \n",
    "    numba_time.append(elapsed) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "gpu_elapsed = pd.DataFrame({\"time\":gpu_time,\"data_size\":total_datasize,'label':\"gpu\"})\n",
    "cpu_elapsed = pd.DataFrame({\"time\":cpu_time,\"data_size\":total_datasize,'label':\"cpu\"})\n",
    "numba_elasped = pd.DataFrame({\"time\":numba_time,\"data_size\":total_datasize,'label':\"numba\"}) \n",
    "result = pd.concat([gpu_elapsed,cpu_elapsed,numba_elasped]).reset_index()\n",
    "sns.lineplot(x= 'data_size',y='time',hue = 'label',data = result,ax = ax )\n",
    "plt.xlabel('Data Size')\n",
    "plt.ylabel(\"Time Elapsed \")\n",
    "plt.title(\"Comparing the speed of matrix multiplication on CPU and GPU\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "#Full - pipeline on GPU \n",
    "reimbursement_tfidf= gpu_vectorizer.fit_transform(cudf.Series(reimbursement_full_address))\n",
    "account_tfidf = gpu_vectorizer.transform(cudf.Series(account_full_address))\n",
    "similarity_matrix = Numba_cuda_cosine_similarity(reimbursement_tfidf,account_tfidf) \n",
    "\n",
    "result = defaultdict(list)\n",
    "#Getting the reimbursement address and state, account address and state \n",
    "for index in range(similarity_matrix.shape[0]):\n",
    "    most_similar_index = similarity_matrix[index].argmax()\n",
    "    result['reimbursement_address'].append(reimbursement_full_address[index]) \n",
    "    result['account_address'].append(account_full_address[most_similar_index])  \n",
    "    result['reimbursment_zip'].append(reimbursement.loc[index,'Provider Zip Code'])\n",
    "    result['account_zip'].append(account.loc[most_similar_index,'ZIP Code']) \n",
    "    result['similarity_score'].append(similarity_matrix[index][most_similar_index])\n",
    "\n",
    "result_df = pd.DataFrame(result).sort_values('similarity_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(result_df.reimbursment_zip,result_df.account_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots(figsize=(10,10))\n",
    "result_df.similarity_score.plot(kind='hist',bins=10,ax=ax)\n",
    "plt.xlabel('Cosine Similarity Score')\n",
    "plt.title('Distribution of cosine similarity score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df.sort_values('similarity_score',ascending=True).head(2).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df.sort_values('similarity_score',ascending=False).head(2).to_markdown())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
