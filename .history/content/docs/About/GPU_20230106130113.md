---
title: "GPU"
weight: 1
# bookFlatSection: false
# bookToc: true
# bookHidden: false
# bookCollapseSection: false
# bookComments: false
# bookSearchExclude: false
---

## Introduction 

Over the past few decades, social science research has faced challenges due to a lack of available data, the cost and time needed to conduct surveys, and limitations on computational power for analysis. These issues were exacerbated by declining survey quality and biases in the characteristics of respondents. There was also no guarantee that long-term, time-consuming surveys would continue to be available due to fiscal austerity (Singleton et al., 2017). However, in recent years, the availability of big data has greatly expanded the resources available to social scientists, allowing them to access a wide range of information about individuals and societies from sources such as social media, mobile devices, and online transactions. The rapid expansion of data is transforming the practice of social science, providing increasingly granular spatial and behavioural profiles about the society and individuals. The difference is not just a matter of scale. The increasing data availability extends beyond the realm of identifying consumer preferences, allowing us to measure social processes and the dynamics of spatial trends in unprecedented detail. 

For example, Trasberg and Cheshire (2021) used a large scale mobility data from mobile applications to explore the activity patterns in London during lockdown, identifying the socio-spatial fragmentation between urban communities. Similarly, Van Dijk (2020) used an annually updated Consumer Register (LCR) to estimate residential moves and the socio-spatial characteristics of the sedentary population in the UK, overcoming the limitations of the traditional census data. Gebru et al. (2020), on the other hand, used a large scale dataset of images from Google Street View to estimate the demographic makeup of a neighborhood. Their results suggested a possibility of using automated systems for monitoring demographics may effectively complement labor-intensive approaches, with the potential to measure demographics with fine spatial resolution, in close to real time.

With the growing availability of data, processing and analyzing large datasets need more computational power than is currently available, with more complex algorithms that need more compute power to run. To overcome this challenge, researchers have turned to a GPU (Graphics Processing Unit) to accelerate massive data parallelism and computation. Therefore, in this chapter, we will introduce the concept of GPU and explain why GPU can be a useful tool for social scientists. In addition, we will provide a brief introduction to the CUDA and RAPIDS package, which is a GPU-accelerated framework that can be used to accelerate the data analysis process. 

## CPU vs GPU 

A CPU is a general-purpose processor that is capable of executing a wide range of tasks, including running operating systems, executing programs, and performing calculations. CPUs are typically designed with a focus on sequential processing, meaning they are optimized for executing instructions one at a time in a specific order. They have a relatively small number of processing cores (usually between 2 and 16) and are capable of performing a wide range of functions.

A GPU, on the other hand, is a specialized processor that is designed specifically for handling graphics and visualizations. GPUs have a large number of processing cores (usually hundreds or thousands) and are optimized for parallel processing, meaning they can perform many calculations simultaneously. This makes them particularly well-suited for tasks that require a lot of processing power, such as rendering 3D graphics, running machine learning algorithms, or performing scientific simulations.

The main difference between CPU and GPU is the designed architecture (Figure 1). GPUs dedicate most of their transistors for ALU units(Arithmetic Logic Unit) which are responsible for performing arithmetic and logical operations, while CPUs reserve most of their transistors for caches and control units which aim to reduce latency within each thread. 

The way that CPUs and GPUs process data is different due to their architectural differences. CPUs are designed to minimize the time it takes to access data (white bars in Figure 2). In a single time slice, a CPU thread tries to get as much work done as possible (green bar). To achieve this, CPUs require low latency, which is achieved through large caches and complex control logic. However, caches work best with only a few threads per core, as switching between threads is expensive.

GPUs, on the other hand, hide instruction and memory latency with computation. In GPUs, each thread is assigned a small amount of memory (blue bar), resulting a much higher latency per thread. However, GPUs have many threads per core, and it can switch from one thread to another at no cost, resulting higher throughput and bandwidth for large data. What this means, in the end, is that we can store more data in the GPU memory and caches, which can be reused for matrix multiplication and operations that are more computationally intensive.

As shown in Figure 2, when thread T1 is waiting for data, another thread T2 begins processing, and so on with T3 and T4. In the meantime, T1 eventually gets the data it needs to process. In this way, latency is hidden by switching to other available work. As a result, GPUs can utilize overlapping concurrent threads to hide latency and are able to run thousands of threads at once.  The best CPUs have about 50GB/s while the best GPUs have 750GB/s memory bandwidth. So the larger your computational operations are in terms of memory, the larger the advantage of GPUs over CPUs. 

We can make the minions' analogy to explain the difference between CPU and GPU. A CPU is like Gru who is considerably intelligent and capable of building fantastic machines, but he can only do one thing at a time. A GPU is like a swarm of minions who are not as intelligent as Gru, but they can do build one thing collectively.


<figure title = "test">
     <p><img src="https://github.com/jasoncpit/GPU-Analytics/blob/master/Pictures/GPU_CPU.png?raw=true">
    <figcaption>
    <b>Figure 1: CPU and GPU archetecture. CPU devote more transistors to control data flow, while GPUs devote more transistors to compute data processing.
    </b> 
    </figcaption>
</figure>


<figure title = "test">
     <p><img src="https://github.com/jasoncpit/GPU-Analytics/blob/master/Pictures/GPU_CPU_process.png?raw=true">
    <figcaption>
    <b>Figure 2: CPU and GPU processor architecture.
    </b> 
    </figcaption>
</figure>




## Is GPU better than CPU?

It is not accurate to say that one is always better than the other, as both CPUs and GPUs have their own strengths and are optimized for different types of tasks. First thing to consider is the scale of the data. A good GPU can read/write its memory much faster than the host CPU can read/write its memory. Given large enough data, GPUs can perform calculations much faster than the host CPU. An example can be observed in Figure 3 - <a href="https://www.mathworks.com/help/parallel-computing/measuring-gpu-performance.html">an example of matrix multiplication on a CPU and a GPU</a>

It depends on the data science project. You need to consider the tradeoffs between speed, reliability, and cost. You may get away without a GPU if your neural network is small in scale. It might be worthwhile to consider investing in a GPU if the neural network of a data scientist includes tons of calculations involving hundreds of thousands of parameters. Typically GPUs are a better bet for fast machine learning since, at its core, data science model training comprises simple matrix math calculations, the speed of which is enhanced when performed in parallel.



<figure title = "test">
     <p><img src="https://github.com/jasoncpit/GPU-Analytics/blob/master/Pictures/CPU_GPU_speed.png?raw=true">
    <figcaption>
    <b>Figure 3: Computational speed between CPU and GPU.
    </b> 
    </figcaption>
</figure>



In general, CPUs are better suited for tasks that require a high level of sequential processing, such as running operating systems, executing programs, and performing calculations. They have a smaller number of processing cores, but these cores are generally more powerful and are capable of executing a wide range of instructions.

GPUs, on the other hand, are better suited for tasks that require a lot of parallel processing, such as rendering 3D graphics, running machine learning algorithms, and performing scientific simulations. They have a large number of processing cores, which are optimized for performing many calculations simultaneously.

So, the choice of which to use depends on the specific requirements of the task at hand. If the task requires a high level of sequential processing, a CPU may be the better choice. If the task requires a lot of parallel processing, a GPU may be more suitable. It is also possible to use both CPUs and GPUs in the same system, with the CPU handling tasks that require sequential processing and the GPU handling tasks that require parallel processing.



**Function** 
- CPU is better at sequential tasks, optimized for single-threaded applications.

- We need to understand the bottleneck of GPU and CPU. 
- GPU is better than CPU when we have a lot of data and we need to do a lot of calculations.
- CPU is better when we are doing a lot of sequential tasks on a small amount of data.

But is it really necessary to use GPU for every task?



## Why GPU is becoming popular - CUDA 



## What are the tools available for using GPU?

- RAPIDS
- TensorFlow
- PyTorch
- Numba
- CuPy
- PyCuda
- PyMC3 

## Choosing the right GPU for your analysis

GPU can be expensive. So, it is important to choose the right GPU for your analysis. 
**Local GPU**
- Not all GPU has the same performance. 
- Not all GPU can be intergrated with the CUDA toolkit.
- For example M1 chips are not compatible with CUDA toolkit.

**Cloud GPU**
- Cloud GPU is a good choice for GPU computing.
- Cloud GPU is cheaper than local GPU.
- Providers: Google Cloud, Amazon Web Services, Microsoft Azure, IBM Cloud, Oracle Cloud, Alibaba Cloud, Tencent Cloud, etc.





## References 


