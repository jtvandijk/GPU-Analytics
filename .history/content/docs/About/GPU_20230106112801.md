---
title: "GPU"
weight: 1
# bookFlatSection: false
# bookToc: true
# bookHidden: false
# bookCollapseSection: false
# bookComments: false
# bookSearchExclude: false
---

## Introduction 

Over the past few decades, social science research has faced challenges due to a lack of available data, the cost and time needed to conduct surveys, and limitations on computational power for analysis. These issues were exacerbated by declining survey quality and biases in the characteristics of respondents. There was also no guarantee that long-term, time-consuming surveys would continue to be available due to fiscal austerity (Singleton et al., 2017). However, in recent years, the availability of big data has greatly expanded the resources available to social scientists, allowing them to access a wide range of information about individuals and societies from sources such as social media, mobile devices, and online transactions. The rapid expansion of data is transforming the practice of social science, providing increasingly granular profiles about the society. The difference is not just a matter of scale. The increasing data availability extends beyond the realm of identifying consumer preferences, allowing us to measure social processes and the dynamics of spatial trends in unprecedented detail. 

For example, Trasberg and Cheshire (2021) used a large scale mobility data from mobile applications to explore the activity patterns in London during lockdown, identifying the socio-spatial fragmentation between urban communities. Similarly, Van Dijk (2020) used an annually updated Consumer Register (LCR) to estimate residential moves and the socio-spatial characteristics of the sedentary population in the UK, overcoming the limitations of the traditional census data. Gebru et al. (2020), on the other hand, used a large scale dataset of images from Google Street View to estimate the demographic makeup of a neighborhood. Their results suggested a possibility of using automated systems for monitoring demographics may effectively complement labor-intensive approaches, with the potential to measure demographics with fine spatial resolution, in close to real time.

With the growing availability of data, processing and analyzing large datasets need more computational power than is currently available, with more complex algorithms that need more compute power to run. To overcome this challenge, researchers have turned to a GPU (Graphics Processing Unit) to accelerate massive data parallelism and computation. Therefore, in this chapter, we will introduce the concept of GPU and explain why GPU can be a useful tool for social scientists. In addition, we will provide a brief introduction to the CUDA and RAPIDS package, which is a GPU-accelerated framework that can be used to accelerate the data analysis process. 

## CPU vs GPU 

A CPU is a general-purpose processor that is capable of executing a wide range of tasks, including running operating systems, executing programs, and performing calculations. CPUs are typically designed with a focus on sequential processing, meaning they are optimized for executing instructions one at a time in a specific order. They have a relatively small number of processing cores (usually between 2 and 16) and are capable of performing a wide range of functions.

A GPU, on the other hand, is a specialized processor that is designed specifically for handling graphics and visualizations. GPUs have a large number of processing cores (usually hundreds or thousands) and are optimized for parallel processing, meaning they can perform many calculations simultaneously. This makes them particularly well-suited for tasks that require a lot of processing power, such as rendering 3D graphics, running machine learning algorithms, or performing scientific simulations.

The main difference between CPU and GPU is the designed architecture (Figure 1). GPUs dedicate most of their transistors for ALU units(Arithmetic Logic Unit) which are responsible for performing arithmetic and logical operations, while CPUs reserve most of their transistors for caches and control units which aim to reduce latency within each thread. 

The way that CPUs and GPUs process data is different due to their architectural differences. CPUs are designed to minimize the time it takes to access data (white bars in Figure 2). In a single time slice, a CPU thread tries to get as much work done as possible (green bar). To achieve this, CPUs require low latency, which is achieved through large caches and complex control logic. However, caches work best with only a few threads per core, as switching between threads is expensive.

GPUs, on the other hand, hide instruction and memory latency with computation. In GPUs, threads are lightweight, so the GPU can switch from one thread to another at no cost, as often as every clock cycle. As shown in Figure 2, when thread T1 is waiting for data, another thread T2 begins processing, and so on with T3 and T4. In the meantime, T1 eventually gets the data it needs to process. In this way, latency is hidden by switching to other available work. As a result, GPUs need many overlapping concurrent threads to hide latency and are able to run thousands of threads at once.

We can make the minions' analogy to explain the difference between CPU and GPU. A CPU is like Gru who is considerably intelligent and capable of building fantastic machines, but he can only do one thing at a time. A GPU is like a crowd of minions who are not as intelligent as Gru, but they can do build one thing collectively.




<figure title = "test">
     <p><img src="https://github.com/jasoncpit/GPU-Analytics/blob/master/Pictures/GPU_CPU.png?raw=true">
    <figcaption>
    <b>Figure 1: CPU and GPU archetecture. CPU devote more transistors to control data flow, while GPUs devote more transistors to compute data processing.
    </b> 
    </figcaption>
</figure>


<figure title = "test">
     <p><img src="https://github.com/jasoncpit/GPU-Analytics/blob/master/Pictures/GPU_CPU_process.png?raw=true">
    <figcaption>
    <b>Figure 2: CPU and GPU processor architecture.
    </b> 
    </figcaption>
</figure>




## Is GPU better than CPU?
Yes and no 

**Function** 
- CPU is better at sequential tasks, optimized for single-threaded applications.

- We need to understand the bottleneck of GPU and CPU. 
- GPU is better than CPU when we have a lot of data and we need to do a lot of calculations.
- CPU is better when we are doing a lot of sequential tasks on a small amount of data.

But is it really necessary to use GPU for every task?

It depends on the data science project. You need to consider the tradeoffs between speed, reliability, and cost. You may get away without a GPU if your neural network is small in scale. It might be worthwhile to consider investing in a GPU if the neural network of a data scientist includes tons of calculations involving hundreds of thousands of parameters. Typically GPUs are a better bet for fast machine learning since, at its core, data science model training comprises simple matrix math calculations, the speed of which is enhanced when performed in parallel.


## Why GPU is becoming popular - CUDA 



## What are the tools available for using GPU?

- RAPIDS
- TensorFlow
- PyTorch
- Numba
- CuPy
- PyCuda
- PyMC3 

## Choosing the right GPU for your analysis

GPU can be expensive. So, it is important to choose the right GPU for your analysis. 
**Local GPU**
- Not all GPU has the same performance. 
- Not all GPU can be intergrated with the CUDA toolkit.
- For example M1 chips are not compatible with CUDA toolkit.

**Cloud GPU**
- Cloud GPU is a good choice for GPU computing.
- Cloud GPU is cheaper than local GPU.
- Providers: Google Cloud, Amazon Web Services, Microsoft Azure, IBM Cloud, Oracle Cloud, Alibaba Cloud, Tencent Cloud, etc.





## References 


