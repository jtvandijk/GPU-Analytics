---
title: "Chapter 1 - Address matching and Geocoding address"
weight: 1
# bookFlatSection: false
# bookToc: true
# bookHidden: false
# bookCollapseSection: false
# bookComments: false
# bookSearchExclude: false
---

## Addresses and Geocoding textual datasets using GPU 

Address matching is an example of a broad class of data science problems known as data linkage. Data linkage problems involve connecting two datasets together by establishing an association between two records based on one or more common properties. In the case of address matching, the common property is the address itself. However, due to the lack of a universal standard for the correct form of the address, as well as the fact that sources commonly store address data in many forms, matching addresses becomes a significantly complicated task that requires a great deal of data preparation and processing. Table 1 provides a summary of the linkage problem:



|Input address string| Reference data to match against| 
| --- | ----------- |
|Unstructured text |Structured, tokenised|
|Messy, containing typos and abbreviations|Clean, standardised, correct (In most cases)| 
|Incomplete| Snapshot of addresses at a given time| 
|Range from historic to very recent addresses, including businesses| Organisation / business names are not always part of the address| 

Table 1: Summary of the address matching problem, [Office for National Statistics](https://www.ons.gov.uk/methodology/methodologicalpublications/generalmethodology/onsworkingpaperseries/onsworkingpaperseriesno17usingdatasciencefortheaddressmatchingservice#:~:text=Address%20matching%20is%20an%20example,common%20property%20of%20the%20data.) 


As we can see, the address matching problem is a very complex problem, the complexity of which is compounded by the fact that data is growing at an exponential rate. Therefore, the objective of this chapter is to demonstrate how to fast we can use GPU to solve the address matching at each step. 

## Address matching pipeline 

The address matching process can be split into three high-level steps:

### Data pre-processing 
At the most fundamental level, we need to prepare the data for the matching process. There are potentially different approach to do this, but the most common approach is to concatenate (join) the address into its constituent parts. Alternatively, the input address can be split into corresponding parts, such as the street name, house number, postcode, and so on. The former approach is more common, but it ignores the information in the data about the address, and makes it impossible to rely on the natural structure of the address to help match the desired address with the input string. The latter approach is more complex, but flexible, it allows for more accurate comparison because comparing tokens precludes the possibility of the same word representing one element of the address being compared against an unrelated element of the address. 


### Candidate address retrieval
In the second step, we need a method to compare the input address with the reference data. The most common approach is to compare each token in the input address with each token in the reference data. This approach is simple, but it can't address the problem of typos and abbreviations. Alternatively, we can use a probabilistic data matching algorithm, such as Fuzzy string matching to accommodate for typos. For instance, “Birmingham ~ Birmingam” is one letter different (i.e. Levenshtein distance). However, in practice, when each record is compared against every other record, the number of comparisons can be very large, thus leading to a very expensive computation. Or instead, we can consider using a Natural Language Processing (NLP) approach to compare the addresses by assuming that the address is a sequence of unstructured text. One of the most common approaches is to convert the address into a vector and then compare the vector similarity (e.g., [TF-IDF](http://www.tfidf.com/)). 

### Scoring and ranking 

The last step in the process is to evaluate and convey quality of the match between the input and the retrieved candidate address in such a way that would be easily understood and useful for users. We can evaluate the quality of the match by comparing the input address with the candidate address. The most common approach is to use a similarity score to evaluate the similarity among all potential candidate addresses. Depending on the application, the similarity score can be a simple percentage or a more complex score. For instance, we can define a threshold for the similarity score, and only return the candidate addresses that have a similarity score above the threshold. We can also evaluate the model performance by validating the results with a ground truth dataset (e.g., address's unique property reference number (UPRN)). 



## Considerations for GPU 

The address matching problem is a computationally intensive problem. The complexity of the problem is compounded by the fact that data is growing at an exponential rate. A core challenge is to understand which part of the process is the most computationally intensive and which part of the process can be parallelized on the GPU.

Figure 1 illustrates a potential data pipeline for the address matching problem. In the first part, we can concatenate the address from its constituent parts, whereby treating each address as a sequence of unstructured text. In the second part, we can use a character-based n-gram TF-IDF to convert the address into a vector. While the terms in TF-IDF are usually words, this is not a requirement. We can use n-grams: sequences of N continuous characters, to convert the address into a vector representation based on the character level. In the third part, we can use a similarity score to evaluate the similarity among all potential candidate addresses. In this case, we can use k-Nearest Neighbors (kNN) to find the k nearest neighbors of the input address, and then return the candidate addresses that have a consine similarity score above the threshold. 

Using TF-IDF with N-Grams as terms to find similar strings transforms the problem into a matrix multiplication problem, which is computationally much cheaper. This approach can significantly reduce the **memory** it takes to compare strings, as compared to the fuzzy string matching algorithm with TF-IDF and nearest neighbors algorithm. Furthermore, using a GPU for matrix multiplication can further enhance the **speed of comparison**. The greater the Levenshtein distance, the more different the strings are. By using a GPU, we can reduce the time it takes to calculate the Levenshtein distance, making the comparison of strings much faster.


![Figure 1: Address matching pipeline](/images/Case_Study/Chapter_1/Address_matching_pipeline.png)

An example of character-based n-gram TF-IDF
```python
text = "Birmingham" 

# Create a list of n-grams
n_grams = [text[i:i+3] for i in range(len(text)-2+1)]

print(n_grams)
#['Bir', 'irm', 'rmi', 'min', 'ing', 'ngh', 'gha', 'ham']

```

## Data 
In this tutorial, I have two data sets. The first is a data set that contains basic hospital account number, name and ownership information. The second data set contains hospital information (called provider) as well as the number of discharges and Medicare payment for a specific Heart Failure procedure. The goal is to match up the hospital reimbursement information with the first data so we have more information to analyze our hospital customers. In this instance, we have 5339 hospital accounts and 2697 hospitals with reimbursement information. 
