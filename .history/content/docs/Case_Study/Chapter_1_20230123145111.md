---
title: "Chapter 1 - Address matching and Geocoding address"
weight: 1
# bookFlatSection: false
# bookToc: true
# bookHidden: false
# bookCollapseSection: false
# bookComments: false
# bookSearchExclude: false
---

## Addresses and Geocoding textual datasets using GPU 

Address matching is an example of a broad class of data science problems known as data linkage. The common aspect of all these problems is that they require an association between data (commonly two sources) to be devised based on some common property of the data. For address matching, the common property is the address itself but, given that there is no universally accepted standard for the “correct” form of the address, and sources commonly store address data in many different forms, matching addresses becomes a significantly complicated task that requires a great deal of data preparation and processing. Table 1 provides a summary of the linkage problem:



|Input address string| Reference data to match against| 
| --- | ----------- |
|Unstructured text |Structured, tokenised|
|Messy, containing typos and abbreviations|Clean, standardised, correct (In most cases)| 
|Incomplete| Snapshot of addresses at a given time| 
|Range from historic to very recent addresses, including businesses| Organisation / business names are not always part of the address| 

Table 1: Summary of the address matching problem, [Office for National Statistics](https://www.ons.gov.uk/methodology/methodologicalpublications/generalmethodology/onsworkingpaperseries/onsworkingpaperseriesno17usingdatasciencefortheaddressmatchingservice#:~:text=Address%20matching%20is%20an%20example,common%20property%20of%20the%20data.) 

The objective of this chapter is to demonstrate how to use GPU to solve the address matching problem.  


The objective of the address index (AI) project is to tackle the issue of there not being a universally accepted standard for what constitutes the correct address for any building or place in the UK, and to develop a methodology which provides high quality outcomes regardless of the input. In its most simplistic form, links (or “matches”) can be completed by comparing unique identifier keys specific to each object, for example, a person’s National Insurance number. However, considerable time and effort must be invested in preparing the data prior to linking, to increase the chance of detecting matches while ensuring accuracy is preserved. 

In this tutorial, I'm experimenting the possibility of using GPU for data linkage. More specifically, we can stress-test the speed differenece and performance between RAPIDS cuML (GPU-package) and Sklearn (CPU-package) on the same ML pipeline.  For this tutorial, I'm using Tesla T4 for the experimentation. 


## Common data linkage problems 
While the focus of this chapter is not on the theory of data linkage, it is important to understand the common problems that arise when attempting to link data. 

## Pipeline for data linkage 

At the most foundemntal level, the goal of data linkage is to compute the similarity between two strings (e.g. Levenshtein, Damerau-Levenshtein, Jaro-Winkler, q-gram, cosine).

One approach we can experiement is to transform each string into some kind of vectors and compute the pair-wise similarity. 

- Load our data 
- Vectorize our data using TF-IDF 
- Compare pair-wise similairty of the data

At each steps, we can compare the compuatation speed differences between PAPIDS cuML and Sklearn.  


## Data 
In this tutorial, I have two data sets. The first is a data set that contains basic hospital account number, name and ownership information. The second data set contains hospital information (called provider) as well as the number of discharges and Medicare payment for a specific Heart Failure procedure. The goal is to match up the hospital reimbursement information with the first data so we have more information to analyze our hospital customers. In this instance, we have 5339 hospital accounts and 2697 hospitals with reimbursement information. 
