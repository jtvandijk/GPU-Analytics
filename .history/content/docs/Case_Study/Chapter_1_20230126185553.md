---
title: "Chapter 1 - Address matching and Geocoding address"
weight: 1
# bookFlatSection: false
# bookToc: true
# bookHidden: false
# bookCollapseSection: false
# bookComments: false
# bookSearchExclude: false
---

## Addresses and Geocoding textual datasets using GPU 

Address matching is an example of a broad class of data science problems known as data linkage. Data linkage problems involve connecting two datasets together by establishing an association between two records based on one or more common properties. In the case of address matching, the common property is the address itself. However, due to the lack of a universal standard for the correct form of the address, as well as the fact that sources commonly store address data in many forms, matching addresses becomes a significantly complicated task that requires a great deal of data preparation and processing. Table 1 provides a summary of the linkage problem:



|Input address string| Reference data to match against| 
| --- | ----------- |
|Unstructured text |Structured, tokenised|
|Messy, containing typos and abbreviations|Clean, standardised, correct (In most cases)| 
|Incomplete| Snapshot of addresses at a given time| 
|Range from historic to very recent addresses, including businesses| Organisation / business names are not always part of the address| 

Table 1: Summary of the address matching problem, [Office for National Statistics](https://www.ons.gov.uk/methodology/methodologicalpublications/generalmethodology/onsworkingpaperseries/onsworkingpaperseriesno17usingdatasciencefortheaddressmatchingservice#:~:text=Address%20matching%20is%20an%20example,common%20property%20of%20the%20data.) 


As we can see, the address matching problem is a very complex problem, the complexity of which is compounded by the fact that data is growing at an exponential rate. Therefore, the objective of this chapter is to demonstrate how to fast we can use GPU to solve the address matching at each step. 

## Address matching pipeline 

The address matching process can be split into three high-level steps:

### Data pre-processing 
At the most fundamental level, we need to prepare the data for the matching process. There are potentially different approach to do this, but the most common approach is to concatenate (join) the address into its constituent parts. Alternatively, the input address can be split into corresponding parts, such as the street name, house number, postcode, and so on. The former approach is more common, but it ignores the information in the data about the address, and makes it impossible to rely on the natural structure of the address to help match the desired address with the input string. The latter approach is more complex, but flexible, it allows for more accurate comparison because comparing tokens precludes the possibility of the same word representing one element of the address being compared against an unrelated element of the address. 


### Candidate address retrieval
In the second step, we need a method to compare the input address with the reference data. The most common approach is to compare each token in the input address with each token in the reference data. This approach is simple, but it can't address the problem of typos and abbreviations. Alternatively, we can use a probabilistic data matching algorithm, such as Fuzzy string matching to accommodate for typos. For instance, “Birmingham ~ Birmingam” is one letter different (i.e. Levenshtein distance). However, in practice, when each record is compared against every other record, the number of comparisons can be very large, thus leading to a very expensive computation. Or instead, we can consider using a Natural Language Processing (NLP) approach to compare the addresses by assuming that the address is a sequence of unstructured text. One of the most common approaches is to convert the address into a vector and then compare the vector similarity (e.g., [TF-IDF](http://www.tfidf.com/)). 

### Scoring and ranking 

The last step in the process is to evaluate and convey quality of the match between the input and the retrieved candidate address in such a way that would be easily understood and useful for users. We can evaluate the quality of the match by comparing the input address with the candidate address. The most common approach is to use a similarity score to evaluate the similarity among all potential candidate addresses. Depending on the application, the similarity score can be a simple percentage or a more complex score. For instance, we can define a threshold for the similarity score, and only return the candidate addresses that have a similarity score above the threshold. We can also evaluate the model performance by validating the results with a ground truth dataset (e.g., address's unique property reference number (UPRN)). 



## Considerations for GPU 

The address matching problem is a computationally intensive problem. The complexity of the problem is compounded by the fact that data is growing at an exponential rate. A core challenge is to understand which part of the process is the most computationally intensive and which part of the process can be parallelized on the GPU.

Figure 1 illustrates a potential data pipeline for the address matching problem. In the first part, we can concatenate the address from its constituent parts, whereby treating each address as a sequence of unstructured text. In the second part, we can use a character-based n-gram TF-IDF to convert the address into a vector. While the terms in TF-IDF are usually words, this is not a requirement. We can use n-grams: sequences of N continuous characters, to convert the address into a vector representation based on the character level. In the third part, we can use a similarity score to evaluate the similarity among all potential candidate addresses. In this case, we can use k-Nearest Neighbors (kNN) to find the k nearest neighbors of the input address, and then return the candidate addresses that have a consine similarity score above the threshold. 

Using TF-IDF with N-Grams as terms to find similar strings transforms the problem into a matrix multiplication problem, which is computationally much cheaper. This approach can significantly reduce the **memory** it takes to compare strings, as compared to the fuzzy string matching algorithm with TF-IDF and nearest neighbors algorithm. Furthermore, using a GPU for matrix multiplication can further enhance the **speed of comparison**. The greater the Levenshtein distance, the more different the strings are. By using a GPU, we can reduce the time it takes to calculate the Levenshtein distance, making the comparison of strings much faster.


![Figure 1: Address matching pipeline](/images/Case_Study/Chapter_1/Address_matching_pipeline.png)

An example of character-based n-gram TF-IDF
```python
text = "Birmingham" 

# Create a list of n-grams
n_grams = [text[i:i+3] for i in range(len(text)-2+1)]

print(n_grams)
#['Bir', 'irm', 'rmi', 'min', 'ing', 'ngh', 'gha', 'ham']

```

## Data 
In this tutorial, we will be using US hospital data. In these examples, we have two data sets. The [first](https://raw.githubusercontent.com/chris1610/pbpython/master/data/hospital_account_info.csv) is an internal data set that contains basic hospital account number, name and ownership information. The [second](https://raw.githubusercontent.com/chris1610/pbpython/master/data/hospital_reimbursement.csv) data set contains hospital information (called provider) as well as the number of discharges and Medicare payment for a specific Heart Failure procedure. The goal is to match up the hospital reimbursement information with the first data so we have more information to analyze our hospital customers. In this instance, we have 5339 hospital accounts and 2697 hospitals with reimbursement information. 


## Step 1: Import Libraries and Data pre-processing 

For the first step, let's compare the speed of computing TF-IDF using Sklearn and RAPIDS cuML module. To make the difference more distinguishable, let's test how the increase of vocabulary size would affect the performance in multiple runs.

```python
# Import libraries 
import cudf
import pandas as pd
from cuml.feature_extraction.text import TfidfVectorizer as GPU_TfidfVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer as CPU_TfidfVectorizer
import time 
import numpy as np
import seaborn as sns 
import matplotlib.pyplot as plt

# Import data
data1_url = "https://raw.githubusercontent.com/chris1610/pbpython/master/data/hospital_account_info.csv"
data2_url = "https://raw.githubusercontent.com/chris1610/pbpython/master/data/hospital_reimbursement.csv"

account = pd.read_csv(data1_url) #Hospital account information
reimbursement = pd.read_csv(data2_url) #Hospital reimbursement information

#Converting facility name, address, city and state into one string 
account_full_address = account.apply(lambda x: " ".join([x['Facility Name'],x['Address'],x['City'],x['State']]), axis=1).tolist() 

reimbursement_full_address = reimbursement.apply(lambda x: " ".join([x['Provider Name'],x['Provider Street Address'],x['Provider City'],x['Provider State']]), axis=1).tolist() 

```

## Step 2: TF-IDF Vectorization - experimenting the effect of data size on computational time

In this step, we will be experimenting the effect of data size on computational time. We will be using the same data set, but we will be increasing the size of the data set by x times in each run. We will be using the same vocabulary size for each run. 

```python
#Inititate sklearn vectoriser and cuml vectosier 

#CPU vectorizer from sklearn 
cpu_vectorizer = CPU_TfidfVectorizer(analyzer='char',ngram_range=(1,2))
#GPU vectorizer from cuml 
gpu_vectorizer = GPU_TfidfVectorizer(analyzer='char',ngram_range=(1,2))

#Here analyzer='char' means we are using character as the input 
#ngram_range = (1,2) means we are looking at both unigram and bigram for the model input 


#Manually inflating number of rows with 10 run times 
total_datasize = []
cpu_time = []
gpu_time = [] 
for run in range(1,10):
  for i in range(1,50):
    #Manually inflating the number of records 
    input = reimbursement_full_address*i
    total_datasize.append(len(input))
    #Cpu runtime --------------------------------  
    start = time.time()
    cpu_output = cpu_vectorizer.fit_transform(input)
    done = time.time()
    elapsed = done - start 
    cpu_time.append(elapsed)

    #gpu runtime -------------------------------- 
    start = time.time()
    #Convert input to cudf series 
    gpu_output = gpu_vectorizer.fit_transform(cudf.Series(input))
    done = time.time()
    elapsed = done - start 
    gpu_time.append(elapsed)

#Create a dataframe to store the results
gpu_elapsed = pd.DataFrame({"time":gpu_time,"data_size":total_datasize,'label':"gpu"})
cpu_elapsed = pd.DataFrame({"time":cpu_time,"data_size":total_datasize,'label':"cpu"})
result = pd.concat([gpu_elapsed,cpu_elapsed]).reset_index()
``` 


```python
fig, ax = plt.subplots(figsize=(10,10))
sns.lineplot(x= 'data_size',y='time',hue = 'label',data = result,ax = ax )
plt.xlabel('Data Size')
plt.ylabel("Time Elapsed ")
plt.title("Comparing the speed of TF-IDF vectorisation on CPU and GPU")
plt.show()
print(cpu_output.shape) #(132153, 874) -> meaning we have 132153 rows of address and 874 characters in the vocabulary as input 
```


<figure title = "test">
     <center>
     <p><img src="https://github.com/jasoncpit/GPU-Analytics/blob/master/Pictures/tf_idf_vec.png?raw=true">
    <figcaption>
    <b>Figure 2: Comparing the speed of TF-IDF vectorisation on CPU and GPU. 
    </b> 
    </figcaption>
    </center>
</figure>

There are few things we can observe the code above. Firstly, the code between the CPU and GPU is almost identical. The only difference is that we are using the functions from different libraries. Secondly, we can see that the GPU is able to process the data much faster than the CPU. On average, it takes less than 0.25 seconds to process around 130 thousand addresses on the GPU. In comparison, it takes 4.5 seconds on CPUs for the same input dataset. Furthermore, we can also observe that the run time of CuML’s TfidfVectorizer is almost constant as the input data size increases, whereas the run time of scikit-learn’s TfidfVectorizer exponetiates. This is because the GPU is able to process the data in parallel, which makes it much more efficient than the CPU. Lastly, 


Now that we have our TF-IDF matrix, we want to use the hospital reimbursement data to find the most relevant address from the hospital data. To do this, we can find the address with the smallest distance (or highest similarity) to our query address. For the second step, let's compare the speed of computing cosine similarity using Sklearn and RAPIDS cuML module. 

## Step 3: Cosine Similarity - experimenting the effect of matrix multiplication on computational time

In this step, we will compare the computation time of calculating cosine similarity between two matrices using Numpy and Cupy from scratch. We will use the TF-IDF matrix we created from the reimbursement data in the previous step as the input, and hospital data as the target. 


```python
#Vectorize the target address
cpu_target =cpu_vectorizer.transform(account_full_address)
gpu_target = gpu_vectorizer.transform(cudf.Series(account_full_address))
```

Remember that the input matrix is a sparse matrix, which means that it contains a lot of zeros. Therefore, we can use the sparse matrix multiplication to calculate the cosine similarity. The formula for cosine similarity is as follows: 


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<script async type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


where $query$ and $target$ are the input matrices, $||query||_2$ and $||target||_2$ are the l2 norm of the input matrices.




```python
import cupy as cp
import numpy as np 
import scipy
import gc
import torch 
from cupyx.scipy.sparse.linalg import norm as cp_norm

def np_cosine_similarity(query, target):
    # Assert that the input matrices have the same number of columns
    assert(query.shape[1] == target.shape[1])

    #Calculate the dot product 
    dot_product = np.dot(query,target.T)

    #Calculate l2 norm for query and target 
    query_norm = scipy.sparse.linalg.norm(query,axis=1)
    target_norm = scipy.sparse.linalg.norm(target,axis=1)

    return dot_product/(query_norm[:,np.newaxis]*target_norm[:,np.newaxis].T)


def cp_cosine_similarity(query, target):
    # Assert that the input matrices have the same number of columns
    assert(query.shape[1] == target.shape[1])
    #Initiate GPU instance 
    with cp.cuda.Device(0):
        #Create memory pool
        pool = cp.get_default_memory_pool()
        pool.set_limit(1e9)  # Set the limit of the memory pool to 1 GB
        
        #Check whether the sparse matrix is compatible with Cupy, if not then convert
        if isinstance(query,scipy.sparse._csr.csr_matrix) and isinstance(target,scipy.sparse._csr.csr_matrix):
        # Convert the input matrices to sparse format and copy to the GPU
            query = cp.sparse.csr_matrix(query, copy=True) 
            target = cp.sparse.csr_matrix(target, copy=True)
        
        # Dot product using cupy.dot()
        dot_product = query.dot(target.T)
        
        # Calculate l2 norm for query and target
        query_norm = cp_norm(query,axis=1)
        target_norm = cp_norm(target,axis=1)
        
        # Compute the cosine similarity
        output = dot_product / (cp.expand_dims(query_norm,axis=1) * cp.expand_dims(target_norm,axis=0))
        
        #Converting back to numpy array
        result = output.get()
        del query, target, dot_product, query_norm, target_norm, output
        gc.collect()
        torch.cuda.empty_cache()
    return result
``` 


